{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta=array([[0.125, 0.25 , 0.125],\n",
      "       [0.125, 0.25 , 0.125]])\n",
      "edge_distribution(eta)=array([[0.25, 0.25],\n",
      "       [0.25, 0.25]])\n"
     ]
    }
   ],
   "source": [
    "beta = 1\n",
    "B = 0\n",
    "kappa = 2\n",
    "# The states are marked mu(x0, k), where x0 is the spin of the root node and k is the number of\n",
    "# leaves that are spin-up\n",
    "multiplicity = np.fromfunction(lambda _, k: scipy.special.comb(kappa, k), (2, kappa+1))\n",
    "eta = multiplicity / (2 ** (kappa+1))\n",
    "print(f'{eta=}')\n",
    "\n",
    "def Hamiltonian(x0, k):\n",
    "    x0 = 2 * x0 - 1\n",
    "    return beta / 2 * x0 * (2 * k - kappa) + B * x0\n",
    "\n",
    "def relative_entropy(p, q):\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def edge_distribution(p):\n",
    "    counts = np.vstack((kappa - np.arange(kappa+1),\n",
    "                        np.arange(kappa+1)))\n",
    "    return p @ counts.T / kappa\n",
    "\n",
    "def target_function(mu):\n",
    "    hamiltonian = np.fromfunction(Hamiltonian, (2, kappa+1))\n",
    "    exp = np.sum(hamiltonian * mu)\n",
    "    rel_entr = relative_entropy(mu, eta)\n",
    "    pi_mu = edge_distribution(mu)\n",
    "    pi_eta = edge_distribution(eta)\n",
    "    marg_rel_entr = relative_entropy(pi_mu, pi_eta)\n",
    "    return exp - rel_entr + marg_rel_entr\n",
    "    \n",
    "def norm_constraint(mu):\n",
    "    return np.sum(mu) - 1\n",
    "\n",
    "# def norm_constraint_grad(mu):\n",
    "#     return mu\n",
    "\n",
    "def admissibility_constraint(mu):\n",
    "    pi_mu = edge_distribution(mu)\n",
    "    return pi_mu[0, 1] - pi_mu[1, 0]\n",
    "\n",
    "# def admissibility_constraint_grad(mu):\n",
    "#     grad_01 = np.concatenate([kappa - np.arange(kappa+1),\n",
    "#                               np.zeros((1, kappa+1))], axis=0)\n",
    "#     grad_10 = np.concatenate([np.zeros((1, kappa+1)),\n",
    "#                               np.arange(kappa+1)], axis=0)\n",
    "#     return grad_01 - grad_10\n",
    "\n",
    "print(f'{edge_distribution(eta)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x0, lam0, patience, eps, verbose=True):\n",
    "\n",
    "    x = x0\n",
    "    lam = lam0\n",
    "    \n",
    "    target = -np.inf\n",
    "    for it in range(patience):\n",
    "        if verbose:\n",
    "            print(f\"{it=}\")\n",
    "\n",
    "        # Redefine the function for scipy.optimize.minimize\n",
    "        # There is probably some fancy functional-programming way to incorporate lambda\n",
    "        # but you get the point.\n",
    "        def proximal_target_function(_x):\n",
    "            _x = _x.reshape((2, kappa+1))\n",
    "            _mu = np.exp(_x)\n",
    "            _norm_constraint = norm_constraint(_mu)\n",
    "            _admissibility_constraint = admissibility_constraint(_mu)\n",
    "            return -target_function(_mu) \\\n",
    "                - lam[0] * _norm_constraint \\\n",
    "                - lam[1] * _admissibility_constraint \\\n",
    "                + _norm_constraint ** 2 / 2 \\\n",
    "                + 1000 * _admissibility_constraint ** 2 / 2\n",
    "        \n",
    "        # Calculate proximal point\n",
    "        res = minimize(proximal_target_function, x0=x.flatten(), method='l-bfgs-b')\n",
    "        if not res.success:\n",
    "            print(f'Proximal Point minimization not successful: {res.message}')\n",
    "            return x, target\n",
    "        new_x = res.x.reshape((2, kappa+1))\n",
    "        \n",
    "        new_mu = np.exp(new_x.reshape(2, kappa+1))\n",
    "        new_target = target_function(new_mu)\n",
    "        _norm_constraint = norm_constraint(new_mu)\n",
    "        _admissibility_constraint = admissibility_constraint(new_mu)\n",
    "        if verbose:\n",
    "            print(f\"{new_target=:.4e}\\t{_norm_constraint=:.4e}\\t{_admissibility_constraint=:.4e}\")\n",
    "            \n",
    "        # Decide whether to terminate\n",
    "        if np.abs(target - new_target) < eps and np.all(np.abs(mu - new_mu) < eps) and np.abs(_norm_constraint) < eps and np.abs(_admissibility_constraint) < eps:\n",
    "            return x, target\n",
    "        target = new_target\n",
    "        x = new_x\n",
    "        mu = new_mu\n",
    "        \n",
    "        # Update lambda\n",
    "        lam[0] = lam[0] - _norm_constraint\n",
    "        lam[1] = lam[1] - 1000 * _admissibility_constraint\n",
    "    print(f'Reached Patience: {new_target=:.4e}\\t{_norm_constraint=:.4e}\\t{_admissibility_constraint=:.4e}')\n",
    "    return x, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.sum(mu)=0.9999997864538266, target=0.43378066628936596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3877483 , 0.10495102, 0.00712468],\n",
       "       [0.00708234, 0.10503461, 0.38805884]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = 1\n",
    "B = 0\n",
    "\n",
    "x0 = np.random.uniform(-10, 10, (2, 3))\n",
    "# x0 = np.zeros((2, kappa+1))\n",
    "\n",
    "x, target = optimize(x0, lam0=np.zeros(2), patience=2000, eps=1e-6, verbose=False)\n",
    "mu = np.exp(x)\n",
    "print(f'{np.sum(mu)=}, {target=}')\n",
    "mu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P(X0, X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi_mu=array([[0.4403988 , 0.05960082],\n",
      "       [0.05960098, 0.44039769]])\n",
      "p_x0=array([0.49999962, 0.49999867]) p_x1=array([0.49999978, 0.49999851])\n",
      "np.outer(p_x0, p_x1)=array([[0.2499997 , 0.24999907],\n",
      "       [0.24999923, 0.24999859]])\n"
     ]
    }
   ],
   "source": [
    "pi_mu = edge_distribution(mu)\n",
    "print(f'{pi_mu=}')\n",
    "p_x0 = np.sum(pi_mu, axis=1)\n",
    "p_x1 = np.sum(pi_mu, axis=0)\n",
    "print(f'{p_x0=}', f'{p_x1=}')\n",
    "print(f'{np.outer(p_x0, p_x1)=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leaf_dist=array([[0.39500674, 0.10499177],\n",
      "       [0.10499177, 0.39500801]])\n",
      "p_x1=array([0.49999962, 0.49999867]) p_x2=array([0.49999978, 0.49999851])\n",
      "np.outer(p_x1, p_x2)=array([[0.2499997 , 0.24999907],\n",
      "       [0.24999923, 0.24999859]])\n"
     ]
    }
   ],
   "source": [
    "mu_edge = np.sum(mu, axis=0)\n",
    "leaf_dist = np.array([[mu_edge[2], mu_edge[1] / 2],\n",
    "                      [mu_edge[1] / 2, mu_edge[0]],])\n",
    "print(f'{leaf_dist=}')\n",
    "p_x1 = np.sum(pi_mu, axis=1)\n",
    "p_x2 = np.sum(pi_mu, axis=0)\n",
    "print(f'{p_x1=}', f'{p_x2=}')\n",
    "print(f'{np.outer(p_x1, p_x2)=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P(X1, X2 | X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_edge=array([0.01420764, 0.20998095, 0.77581142])\n",
      "leaf_dist=array([[0.77581142, 0.10499047],\n",
      "       [0.10499047, 0.01420764]])\n",
      "p_x1=array([0.49999962, 0.49999867]) p_x2=array([0.49999978, 0.49999851])\n",
      "np.outer(p_x1, p_x2)=array([[0.2499997 , 0.24999907],\n",
      "       [0.24999923, 0.24999859]])\n"
     ]
    }
   ],
   "source": [
    "x0 = 1\n",
    "mu_edge = mu[x0] / np.sum(mu, axis=1)[x0]\n",
    "print(f'{mu_edge=}')\n",
    "leaf_dist = np.array([[mu_edge[2], mu_edge[1] / 2],\n",
    "                      [mu_edge[1] / 2, mu_edge[0]],])\n",
    "print(f'{leaf_dist=}')\n",
    "p_x1 = np.sum(pi_mu, axis=1)\n",
    "p_x2 = np.sum(pi_mu, axis=0)\n",
    "print(f'{p_x1=}', f'{p_x2=}')\n",
    "print(f'{np.outer(p_x1, p_x2)=}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
